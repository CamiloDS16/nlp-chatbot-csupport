{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Modeling: Sentiment Analysis For Customer Interactions In X (Formerly Twitter)\n",
    "\n",
    "This notebook is structured to guide through the preprocessing and modeling stages of a sentiment analysis project. The primary objective is to categorize X (formerly Twitter) customer support interactions into distinct sentiment classes. This involves transforming cleaned tweet data for machine learning applications and performing sentiment analysis to extract meaningful business insights.\n",
    "\n",
    "#### Preprocessing\n",
    "- **Objective**: Ready the cleaned dataset for detailed sentiment analysis and feature extraction.\n",
    "- **Key Steps**:\n",
    "  - Application of advanced NLP techniques like lemmatization and removal of stopwords to refine the text data.\n",
    "  - Execution of feature engineering to extract significant attributes from the data, including text length, frequency of product mentions, and sentiment scores.\n",
    "  - Development of additional derived features such as part-of-speech tags and named entity recognition to enhance the dataset's richness.\n",
    "\n",
    "#### Feature Extraction and Selection\n",
    "- **Objective**: Extract and identify key features for the sentiment analysis model.\n",
    "- **Methodology**:\n",
    "  - Employment of TF-IDF vectorization to numerically represent text data, highlighting word significance within the dataset.\n",
    "  - Incorporation of count-based features like noun and adjective counts, adding depth to the model's understanding.\n",
    "  - Selection of a diversified set of text-based and derived features to form a comprehensive input for the model.\n",
    "\n",
    "#### Model Building and Evaluation\n",
    "- **Objective**: Develop and evaluate models for classifying tweets into sentiment categories.\n",
    "- **Approach**:\n",
    "  - Exploration of various machine learning models including Logistic Regression, Support Vector Machine, Random Forest, and Gradient Boosting Machines.\n",
    "  - Assessment of model performance using metrics such as accuracy, precision, recall, and F1-score to gauge effectiveness.\n",
    "  - Optimization of model parameters and feature selection to enhance accuracy and performance.\n",
    "\n",
    "#### Sentiment Classification\n",
    "- **Objective**: Precise classification of customer interactions into positive, negative, or neutral sentiments.\n",
    "- **Details**:\n",
    "  - Integration of trained models for predicting sentiment labels on new data.\n",
    "  - Analysis of model predictions to gain insights into customer sentiment trends and brand performance.\n",
    "\n",
    "#### Final Model Selection and Deployment Considerations\n",
    "- **Objective**: Identify the most effective model and plan its deployment.\n",
    "- **Strategy**:\n",
    "  - Comparison of different models to select the most suitable one for sentiment classification.\n",
    "  - Discussion of potential deployment methodologies, including options for real-time analysis and integration within customer support frameworks.\n",
    "\n",
    "This notebook underscores the significance of meticulous data preparation, strategic feature engineering, and judicious model selection in sentiment analysis, aiming to showcase advanced data science proficiency and a pragmatic approach to addressing real-world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for processing\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import load, dump\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import logging\n",
    "import warnings\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# set up spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Cleaned Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 20:54:48,857 - INFO - Starting execution of load_data\n",
      "2023-12-20 20:54:49,482 - INFO - Data loading completed successfully\n",
      "2023-12-20 20:54:49,485 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/interim/cleaned_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:11:45</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:08:27</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i have sent several private messages and no on...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:49:35</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>i did</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:45:10</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is the worst customer service</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>2017-10-31 22:04:47</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>you gonna magically change your connectivity f...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id           created_at   \n",
       "0         2     115712  2017-10-31 22:11:45  \\\n",
       "1         3     115712  2017-10-31 22:08:27   \n",
       "2         5     115712  2017-10-31 21:49:35   \n",
       "3         8     115712  2017-10-31 21:45:10   \n",
       "4        12     115713  2017-10-31 22:04:47   \n",
       "\n",
       "                                                text response_tweet_id   \n",
       "0      @sprintcare and how do you propose we do that               NaN  \\\n",
       "1  @sprintcare I have sent several private messag...                 1   \n",
       "2                                 @sprintcare I did.                 4   \n",
       "3          @sprintcare is the worst customer service            9,6,10   \n",
       "4  @sprintcare You gonna magically change your co...          11,13,14   \n",
       "\n",
       "   in_response_to_tweet_id                                       cleaned_text   \n",
       "0                      1.0                  and how do you propose we do that  \\\n",
       "1                      4.0  i have sent several private messages and no on...   \n",
       "2                      6.0                                              i did   \n",
       "3                      NaN                      is the worst customer service   \n",
       "4                     15.0  you gonna magically change your connectivity f...   \n",
       "\n",
       "   sentiment  message_length  \n",
       "0     0.0000              33  \n",
       "1    -0.2960              70  \n",
       "2     0.0000               5  \n",
       "3    -0.6249              29  \n",
       "4     0.0000              71  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_text\n",
       "<class 'str'>    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['cleaned_text'].apply(type).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing:\n",
    "\n",
    "We will perform a series of steps to transform the data for modeling by doing this, we ensure the consistency on responses. We will also add some engineered features that will enhance the model for the response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting cleaned_text values to str in case there are other datatypes\n",
    "df['cleaned_text'] = df['cleaned_text'].astype(str)\n",
    "\n",
    "# applying preprocessing\n",
    "df['processed'] = df['cleaned_text'].apply(preprocess_text)\n",
    "df['processed_text'] = df['processed'].apply(lambda x: x['processed_text'])\n",
    "df['pos_tags'] = df['processed'].apply(lambda x: x['pos_tags'])\n",
    "df['noun_count'] = df['pos_tags'].apply(lambda tags: tags.count('NOUN'))\n",
    "df['adj_count'] = df['pos_tags'].apply(lambda tags: tags.count('ADJ'))\n",
    "# text complexity\n",
    "df['text_complexity'] = df['processed_text'].apply(lambda x: len(set(x.split())) / len(x.split()) if x.split() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:08:59,878 - INFO - DataFrame saved successfully to ../data/processed/processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved at: ../data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# saving preprocessed data to csv\n",
    "folder_path2 = '../data/'  # Adjust the path as needed\n",
    "file_name2 = 'processed/processed_data.csv'\n",
    "full_path2 = save_data(df, folder_path2, file_name2)\n",
    "\n",
    "if full_path2:\n",
    "    print(f\"DataFrame saved at: {full_path2}\")\n",
    "else:\n",
    "    print(\"Failed to save the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NER\n",
    "df['entities'] = df['text'].apply(extract_entities)\n",
    "# count product mention\n",
    "df['product_mentions'] = df['entities'].apply(lambda ents: sum('PRODUCT' in ent for ent in ents))\n",
    "# text length in processed-lemmatized text\n",
    "df['text_length'] = df['processed_text'].apply(len)\n",
    "# brands count\n",
    "df['brand_mentions'] = df['entities'].apply(lambda ents: sum('ORG' in ent for ent in ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:20:41,397 - INFO - DataFrame saved successfully to ../data/processed/processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved at: ../data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# saving preprocessed data to csv\n",
    "folder_path2 = '../data/'  # Adjust the path as needed\n",
    "file_name2 = 'processed/processed_data.csv'\n",
    "full_path2 = save_data(df, folder_path2, file_name2)\n",
    "\n",
    "if full_path2:\n",
    "    print(f\"DataFrame saved at: {full_path2}\")\n",
    "else:\n",
    "    print(\"Failed to save the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 10:25:52,083 - INFO - Starting execution of load_data\n",
      "2023-12-12 10:25:53,212 - INFO - Data loading completed successfully\n",
      "2023-12-12 10:25:53,217 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/processed/processed_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dependent variable\n",
    "def categorize_sentiment(score, pos_threshold=0.1, neg_threshold=-0.1):\n",
    "    \"\"\"\n",
    "    Categorize sentiment score into classes with error handling and logging.\n",
    "    Args:\n",
    "    score (float): Sentiment score.\n",
    "    pos_threshold (float): Threshold for positive sentiment.\n",
    "    neg_threshold (float): Threshold for negative sentiment.\n",
    "    Returns:\n",
    "    str: Sentiment category ('Positive', 'Negative', 'Neutral').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if score > pos_threshold:\n",
    "            sentiment = 'Positive'\n",
    "        elif score < neg_threshold:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in categorizing sentiment: {e}\")\n",
    "        return 'Neutral'\n",
    "\n",
    "# applying the function to create a derived sentiment column\n",
    "df['derived_sentiment'] = df['sentiment'].apply(categorize_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message_length</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>text_complexity</th>\n",
       "      <th>entities</th>\n",
       "      <th>product_mentions</th>\n",
       "      <th>text_length</th>\n",
       "      <th>brand_mentions</th>\n",
       "      <th>derived_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:11:45</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>33</td>\n",
       "      <td>{'processed_text': 'propose', 'pos_tags': ['CC...</td>\n",
       "      <td>propose</td>\n",
       "      <td>[CCONJ, SCONJ, AUX, PRON, VERB, PRON, VERB, PRON]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:08:27</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i have sent several private messages and no on...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>70</td>\n",
       "      <td>{'processed_text': 'send private message respo...</td>\n",
       "      <td>send private message respond usual</td>\n",
       "      <td>[PRON, AUX, VERB, ADJ, ADJ, NOUN, CCONJ, DET, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:49:35</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>i did</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>{'processed_text': '', 'pos_tags': ['PRON', 'V...</td>\n",
       "      <td></td>\n",
       "      <td>[PRON, VERB]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:45:10</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is the worst customer service</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>29</td>\n",
       "      <td>{'processed_text': 'bad customer service', 'po...</td>\n",
       "      <td>bad customer service</td>\n",
       "      <td>[AUX, DET, ADJ, NOUN, NOUN]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>2017-10-31 22:04:47</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>you gonna magically change your connectivity f...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "      <td>{'processed_text': 'gon na magically change co...</td>\n",
       "      <td>gon na magically change connectivity family</td>\n",
       "      <td>[PRON, VERB, PART, ADV, VERB, PRON, NOUN, ADP,...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id           created_at   \n",
       "0         2     115712  2017-10-31 22:11:45  \\\n",
       "1         3     115712  2017-10-31 22:08:27   \n",
       "2         5     115712  2017-10-31 21:49:35   \n",
       "3         8     115712  2017-10-31 21:45:10   \n",
       "4        12     115713  2017-10-31 22:04:47   \n",
       "\n",
       "                                                text response_tweet_id   \n",
       "0      @sprintcare and how do you propose we do that               NaN  \\\n",
       "1  @sprintcare I have sent several private messag...                 1   \n",
       "2                                 @sprintcare I did.                 4   \n",
       "3          @sprintcare is the worst customer service            9,6,10   \n",
       "4  @sprintcare You gonna magically change your co...          11,13,14   \n",
       "\n",
       "   in_response_to_tweet_id                                       cleaned_text   \n",
       "0                      1.0                  and how do you propose we do that  \\\n",
       "1                      4.0  i have sent several private messages and no on...   \n",
       "2                      6.0                                              i did   \n",
       "3                      NaN                      is the worst customer service   \n",
       "4                     15.0  you gonna magically change your connectivity f...   \n",
       "\n",
       "   sentiment  message_length   \n",
       "0     0.0000              33  \\\n",
       "1    -0.2960              70   \n",
       "2     0.0000               5   \n",
       "3    -0.6249              29   \n",
       "4     0.0000              71   \n",
       "\n",
       "                                           processed   \n",
       "0  {'processed_text': 'propose', 'pos_tags': ['CC...  \\\n",
       "1  {'processed_text': 'send private message respo...   \n",
       "2  {'processed_text': '', 'pos_tags': ['PRON', 'V...   \n",
       "3  {'processed_text': 'bad customer service', 'po...   \n",
       "4  {'processed_text': 'gon na magically change co...   \n",
       "\n",
       "                                processed_text   \n",
       "0                                      propose  \\\n",
       "1           send private message respond usual   \n",
       "2                                                \n",
       "3                         bad customer service   \n",
       "4  gon na magically change connectivity family   \n",
       "\n",
       "                                            pos_tags  noun_count  adj_count   \n",
       "0  [CCONJ, SCONJ, AUX, PRON, VERB, PRON, VERB, PRON]           0          0  \\\n",
       "1  [PRON, AUX, VERB, ADJ, ADJ, NOUN, CCONJ, DET, ...           2          3   \n",
       "2                                       [PRON, VERB]           0          0   \n",
       "3                        [AUX, DET, ADJ, NOUN, NOUN]           2          1   \n",
       "4  [PRON, VERB, PART, ADV, VERB, PRON, NOUN, ADP,...           2          1   \n",
       "\n",
       "   text_complexity entities  product_mentions  text_length  brand_mentions   \n",
       "0              1.0       []                 0            7               0  \\\n",
       "1              1.0       []                 0           34               0   \n",
       "2              0.0       []                 0            0               0   \n",
       "3              1.0       []                 0           20               0   \n",
       "4              1.0       []                 0           43               0   \n",
       "\n",
       "  derived_sentiment  \n",
       "0           Neutral  \n",
       "1          Negative  \n",
       "2           Neutral  \n",
       "3          Negative  \n",
       "4           Neutral  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data validation check\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering:\n",
    "\n",
    "We will be creating main features for modeling(TF-IDF features) with TfidfVectorizer. Then, we will add the engineered features created previously into a sparse matrix so that the structure can be input into the ML models that will be trained and evaluated for the task. In order to create the matrix we will employ hstack function from the module scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['processed_text'].fillna('')\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "try:\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "# Combine TF-IDF with other features\n",
    "    additional_features = df[['noun_count', 'product_mentions', 'text_length', 'brand_mentions', 'adj_count', 'text_complexity']].values\n",
    "    X_combined = hstack([X_tfidf, additional_features])\n",
    "except Exception as e: \n",
    "    logging.error(f\"Error while performing TfidfVectorizer and/or combining features: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data: Train & Test\n",
    "\n",
    "We will proceed to split the data into train and test so that we hold onto a set of the data to evaluate the models later on and avoid data leakage and biased models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:31:38,304 - INFO - Data successfully split into train and test sets.\n",
      "2023-12-20 21:31:38,305 - INFO - Split data function applied successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    y = df['derived_sentiment']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X_combined, y, test_size=0.3)\n",
    "    logging.info(\"Split data function applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while splitting data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features: \n",
    "\n",
    "Scaling is a crucial step before training a ML model to ensure the features are within the same mean and std. Below, we will extract the count-based features (features extracted previously and stacked horizontally with main feature: TF-IDF). Then, we will use MinMaxScaler to standardize them and finally stack them back with the main and already normalized TF-IDF features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:37:09,323 - INFO - Count-based features scaled successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# number of count-based features\n",
    "num_count_features = 6\n",
    "\n",
    "try: # Extract count-based features from the end of each row in X_train and X_test\n",
    "    X_train_counts = X_train[:, -num_count_features:]\n",
    "    X_test_counts = X_test[:, -num_count_features:]\n",
    "\n",
    "    # Normalize these features\n",
    "    scaler = MaxAbsScaler()\n",
    "    X_train_counts_scaled = scaler.fit_transform(X_train_counts)\n",
    "    X_test_counts_scaled = scaler.transform(X_test_counts)\n",
    "\n",
    "    # Recombine with the TF-IDF features\n",
    "    X_train_scaled = hstack([X_train[:, :-num_count_features], X_train_counts_scaled])\n",
    "    X_test_scaled = hstack([X_test[:, :-num_count_features], X_test_counts_scaled])\n",
    "    logging.info(\"Count-based features scaled successfully\")\n",
    "except Exception as e: \n",
    "    logging.error(f\"Error while scaling count-based features: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding y_train and y_test for XGBoost Modeling\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Data: \n",
    "\n",
    "Below we will leverage the module joblib to save the train and test sets for future use. This step is to avoid repetitive processes and ensure scalability and seamlessly collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 21:42:17,914 - INFO - X_train_scaled saved successfully at ../data/processed/X_train_scaled.joblib\n",
      "2023-12-20 21:42:17,917 - INFO - X_test_scaled saved successfully at ../data/processed/X_test_scaled.joblib\n",
      "2023-12-20 21:42:17,922 - INFO - y_train saved successfully at ../data/processed/y_train.joblib\n",
      "2023-12-20 21:42:17,927 - INFO - y_test saved successfully at ../data/processed/y_test.joblib\n",
      "2023-12-20 21:42:17,928 - INFO - y_train_encoded saved successfully at ../data/processed/y_train_encoded.joblib\n",
      "2023-12-20 21:42:17,930 - INFO - y_test_encoded saved successfully at ../data/processed/y_test_encoded.joblib\n"
     ]
    }
   ],
   "source": [
    "# Paths for saving the datasets\n",
    "X_train_path = '../data/processed/X_train_scaled.joblib'\n",
    "X_test_path = '../data/processed/X_test_scaled.joblib'\n",
    "y_train_path = '../data/processed/y_train.joblib'\n",
    "y_test_path = '../data/processed/y_test.joblib'\n",
    "y_train_encoded_path = '../data/processed/y_train_encoded.joblib'\n",
    "y_test_encoded_path = '../data/processed/y_test_encoded.joblib'\n",
    "\n",
    "# Saving the datasets\n",
    "try:\n",
    "    dump(X_train_scaled, X_train_path)\n",
    "    logging.info(f\"X_train_scaled saved successfully at {X_train_path}\")\n",
    "\n",
    "    dump(X_test_scaled, X_test_path)\n",
    "    logging.info(f\"X_test_scaled saved successfully at {X_test_path}\")\n",
    "\n",
    "    dump(y_train, y_train_path)\n",
    "    logging.info(f\"y_train saved successfully at {y_train_path}\")\n",
    "\n",
    "    dump(y_test, y_test_path)\n",
    "    logging.info(f\"y_test saved successfully at {y_test_path}\")\n",
    "\n",
    "    dump(y_train_encoded, y_train_encoded_path)\n",
    "    logging.info(f\"y_train_encoded saved successfully at {y_train_encoded_path}\")\n",
    "\n",
    "    dump(y_test_encoded, y_test_encoded_path)\n",
    "    logging.info(f\"y_test_encoded saved successfully at {y_test_encoded_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while saving datasets: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building, Training, and Testing: Sentiment Analysis Project\n",
    "\n",
    "This section of the notebook is dedicated to building, training, and testing various machine learning models for sentiment analysis. Our goal is to classify Twitter customer support interactions into sentiment categories: positive, negative, or neutral. We have chosen four models for this task, each with distinct characteristics and strengths:\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "- **Approach**: We will tune hyperparameters like regularization strength (C) and iteration count, striving for a balance between model simplicity and predictive performance.\n",
    "\n",
    "#### 2. Support Vector Machine (SVM)\n",
    "- **Approach**: We'll explore both linear and non-linear kernels, aiming to capture complex patterns in the data while maintaining model efficiency.\n",
    "\n",
    "#### 3. Random Forest Classifier\n",
    "- **Approach**: We will focus on tuning tree-specific parameters like the number of trees and tree depth to optimize performance and prevent overfitting.\n",
    "\n",
    "#### 4. Gradient Boosting Machines (XGBoost)\n",
    "- **Approach**: We'll implement careful tuning of learning rate, number of estimators, and tree complexity, aiming to enhance the model's ability to sequentially learn from misclassified data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing and Evaluation:\n",
    "For each model, we'll perform the following:\n",
    "- **Cross-Validation**: To ensure robustness and generalizability, we'll use cross-validation techniques during hyperparameter tuning.\n",
    "- **Model Evaluation**: Post-training, we'll assess each model on the test dataset using metrics such as accuracy, precision, recall, and F1-score, providing a holistic view of each model's performance.\n",
    "\n",
    "The selection of these models demonstrates a strategic approach to tackling a real-world sentiment analysis task, showcasing a solid grasp of data science principles and the ability to apply different machine learning techniques effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 09:41:32,545 - INFO - X_train_scaled loaded successfully.\n",
      "2023-12-21 09:41:32,549 - INFO - X_test_scaled loaded successfully.\n",
      "2023-12-21 09:41:32,557 - INFO - y_train loaded successfully.\n",
      "2023-12-21 09:41:32,561 - INFO - y_test loaded successfully.\n",
      "2023-12-21 09:41:32,565 - INFO - y_train_encoded loaded successfully.\n",
      "2023-12-21 09:41:32,569 - INFO - y_test_encoded loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "# Paths where the datasets were saved\n",
    "X_train_path = '../data/processed/X_train_scaled.joblib'\n",
    "X_test_path = '../data/processed/X_test_scaled.joblib'\n",
    "y_train_path = '../data/processed/y_train.joblib'\n",
    "y_test_path = '../data/processed/y_test.joblib'\n",
    "y_train_encoded_path = '../data/processed/y_train_encoded.joblib'\n",
    "y_test_encoded_path = '../data/processed/y_test_encoded.joblib'\n",
    "\n",
    "# Loading the datasets\n",
    "try:\n",
    "    X_train_scaled = load(X_train_path)\n",
    "    logging.info(\"X_train_scaled loaded successfully.\")\n",
    "\n",
    "    X_test_scaled = load(X_test_path)\n",
    "    logging.info(\"X_test_scaled loaded successfully.\")\n",
    "\n",
    "    y_train = load(y_train_path)\n",
    "    logging.info(\"y_train loaded successfully.\")\n",
    "\n",
    "    y_test = load(y_test_path)\n",
    "    logging.info(\"y_test loaded successfully.\")\n",
    "\n",
    "    y_train_encoded = load(y_train_encoded_path)\n",
    "    logging.info(\"y_train_encoded loaded successfully.\")\n",
    "\n",
    "    y_test_encoded = load(y_test_encoded_path)\n",
    "    logging.info(\"y_test_encoded loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading datasets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty DataFrame to store all model scores\n",
    "all_model_scores = pd.DataFrame(columns=['Model', 'F1 Score', 'Accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 09:43:58,983 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "logreg_scores = evaluate_with_cv(logreg_model, X_train_scaled, y_train, \"Logistic Regression\")\n",
    "\n",
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, pd.DataFrame([logreg_scores])], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:50:17,832 - ERROR - Error appending model scores: cannot concatenate object of type '<class 'dict'>'; only Series and DataFrame objs are valid\n"
     ]
    }
   ],
   "source": [
    "# stratified sampling to optimize training times\n",
    "sample_size = 0.5\n",
    "\n",
    "# Perform stratified sampling\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=1 - sample_size, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# initializing SVM - classifier model\n",
    "svc_model = SVC(kernel='linear', cache_size=1000, tol=0.01)\n",
    "\n",
    "# Evaluate the model\n",
    "svc_scores = evaluate_with_cv(svc_model, X_train_sampled, y_train_sampled, \"Support Vector Classifier (SVM)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 12:54:04,342 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, pd.DataFrame([svc_scores])], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 13:28:49,297 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_scores = evaluate_with_cv(rf_model, X_train_sampled, y_train_sampled, \"Random Forest Classifier\")\n",
    "\n",
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, pd.DataFrame([rf_scores])], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 13:59:35,457 - INFO - XGBoost Classifier scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with encoded labels\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Evaluate the model\n",
    "try:\n",
    "    xgb_scores = evaluate_with_cv(xgb_model, X_train_scaled, y_train_encoded,  \"XGBoost Classifier\")\n",
    "    all_model_scores = pd.concat([all_model_scores, pd.DataFrame([xgb_scores])], ignore_index=True)\n",
    "    logging.info(\"XGBoost Classifier scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error evaluating XGBoost Classifier: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 17:01:26,105 - INFO - Columns dropped successfuly. Results DataFrame is completed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    all_model_scores = all_model_scores.drop(columns=[\"F1 Score\", \"Accuracy\", \"Recall\", \"Precision\"], axis=1)\n",
    "\n",
    "    all_model_scores\n",
    "    logging.info(\"Columns dropped successfuly. Results DataFrame is completed\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while dropping columns: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_precision_macro</th>\n",
       "      <th>train_recall_macro</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.775846</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.771656</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.765671</td>\n",
       "      <td>0.766945</td>\n",
       "      <td>0.761292</td>\n",
       "      <td>0.761228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Classifier (SVM)</td>\n",
       "      <td>0.778529</td>\n",
       "      <td>0.781786</td>\n",
       "      <td>0.774570</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.763743</td>\n",
       "      <td>0.765967</td>\n",
       "      <td>0.759453</td>\n",
       "      <td>0.758924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.992486</td>\n",
       "      <td>0.992679</td>\n",
       "      <td>0.992413</td>\n",
       "      <td>0.992508</td>\n",
       "      <td>0.719486</td>\n",
       "      <td>0.718009</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.715362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost Classifier</td>\n",
       "      <td>0.788732</td>\n",
       "      <td>0.795321</td>\n",
       "      <td>0.784709</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>0.755800</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>0.751367</td>\n",
       "      <td>0.750897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model  train_accuracy  train_precision_macro   \n",
       "0              Logistic Regression        0.775846               0.777486  \\\n",
       "1  Support Vector Classifier (SVM)        0.778529               0.781786   \n",
       "2         Random Forest Classifier        0.992486               0.992679   \n",
       "3               XGBoost Classifier        0.788732               0.795321   \n",
       "\n",
       "   train_recall_macro  train_f1_macro  test_accuracy  test_precision_macro   \n",
       "0            0.771656        0.771761       0.765671              0.766945  \\\n",
       "1            0.774570        0.774476       0.763743              0.765967   \n",
       "2            0.992413        0.992508       0.719486              0.718009   \n",
       "3            0.784709        0.785260       0.755800              0.759700   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  \n",
       "0           0.761292       0.761228  \n",
       "1           0.759453       0.758924  \n",
       "2           0.715926       0.715362  \n",
       "3           0.751367       0.750897  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 17:08:10,614 - INFO - DataFrame saved successfully to ../models/default_metrics.csv\n",
      "2023-12-21 17:08:10,615 - INFO - Function applied successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    save_data(df=all_model_scores, folder_path=\"../models/\", file_name=\"default_metrics.csv\")\n",
    "    logging.info(\"Function applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Error while applying function: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tunning:\n",
    "\n",
    "Next, we will tune the models, evaluate them and select the best performing model in the unseen test set. The process will use RandomizedSearchCV as a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty DataFrame to store all tunned model scores \n",
    "all_model_scores2 = pd.DataFrame(columns=['Model', 'F1 Score', 'Accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 17:07:37,614 - INFO - Hyperparameter tunning applied successfully\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Adjusted Hyperparameter Distributions\n",
    "param_dist_logreg = {\n",
    "    'C': loguniform(1e-2, 1e2),  # Regularization strength\n",
    "    # Chosen solvers that are compatible with 'l2' penalty\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag'],  \n",
    "    'penalty': ['l2']  # Only 'l2' penalty is included\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    logreg,\n",
    "    param_distributions=param_dist_logreg,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
    "    refit='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "try:\n",
    "    random_search_logreg.fit(X_train_sampled, y_train_sampled)\n",
    "    best_logreg = random_search_logreg.best_estimator_\n",
    "    logging.info(\"Hyperparameter tunning applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while performing hyperparameter tunning: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned LogReg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 21:56:35,235 - INFO - Models saved successfully at ../models/random_search_logreg.joblib and ../models/best_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "random_search_logreg_path = '../models/random_search_logreg.joblib'\n",
    "best_logreg_path = \"../models/best_logreg.joblib\"\n",
    "\n",
    "try:\n",
    "    dump(random_search_logreg, random_search_logreg_path)\n",
    "    dump(best_logreg, best_logreg_path)\n",
    "    logging.info(f\"Models saved successfully at {random_search_logreg_path} and {best_logreg_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the models: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for LogReg to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 22:05:37,431 - INFO - Best Logistic Regression model evaluated successfully and added to DataFrame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logreg_results = evaluate_model(best_logreg, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    # Adding logreg scores to a df\n",
    "    all_model_scores2 = pd.concat([all_model_scores2, pd.DataFrame([logreg_results])], ignore_index=True)\n",
    "    logging.info(\"Best Logistic Regression model evaluated successfully and added to DataFrame\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while evaluating the model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2023-12-23 15:42:29,271 - INFO - Hyperparameter tuning for Random Forest completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=150,\n",
    "    cv=5,\n",
    "    scoring={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_macro': 'precision_macro',\n",
    "        'recall_macro': 'recall_macro',\n",
    "        'f1_macro': 'f1_macro'\n",
    "    },\n",
    "    refit='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "try:\n",
    "    random_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "    best_rf = random_search_rf.best_estimator_\n",
    "    logging.info(\"Hyperparameter tuning for Random Forest completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during hyperparameter tuning for Random Forest: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 16:57:45,664 - INFO - Models saved successfully at ../models/random_search_rf.joblib and ../models/best_rf.joblib\n"
     ]
    }
   ],
   "source": [
    "# path to model\n",
    "random_search_rf_path = '../models/random_search_rf.joblib'\n",
    "best_rf_path = \"../models/best_rf.joblib\"\n",
    "\n",
    "try:\n",
    "    dump(random_search_rf, random_search_rf_path)\n",
    "    dump(best_rf, best_rf_path)\n",
    "    logging.info(f\"Models saved successfully at {random_search_rf_path} and {best_rf_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the models: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 17:29:10,400 - INFO - Best Random Forest model evaluated successfully and added to DataFrame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rf_results = evaluate_model(best_rf, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "    # Adding random forest scores to a df\n",
    "    all_model_scores2 = pd.concat([all_model_scores2, pd.DataFrame([rf_results])], ignore_index=True)\n",
    "    logging.info(\"Best Random Forest model evaluated successfully and added to DataFrame\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while evaluating the model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning XGBoost Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding sampled y_train for XGBoost \n",
    "label_encoder2 = LabelEncoder()\n",
    "y_train_sampled_encoded = label_encoder2.fit_transform(y_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 16:55:03,661 - INFO - Hyperparameter tuning for XGBoost completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Expanded hyperparameter distributions\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': randint(100, 300),  \n",
    "    'learning_rate': uniform(0.01, 0.3), \n",
    "    'max_depth': randint(3, 15),         \n",
    "    'subsample': uniform(0.7, 0.3),      \n",
    "    'colsample_bytree': uniform(0.7, 0.3), \n",
    "    'gamma': uniform(0, 5)               \n",
    "}\n",
    "\n",
    "# XGBoost model\n",
    "xgb = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# RandomizedSearchCV setup with expanded hyperparameters\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=100,  \n",
    "    cv=5,\n",
    "    scoring={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_macro': 'precision_macro',\n",
    "        'recall_macro': 'recall_macro',\n",
    "        'f1_macro': 'f1_macro'\n",
    "    },\n",
    "    refit='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# hyperparameter tuning\n",
    "try:\n",
    "    random_search_xgb.fit(X_train_sampled, y_train_sampled_encoded)\n",
    "    best_xgb = random_search_xgb.best_estimator_\n",
    "    logging.info(\"Hyperparameter tuning for XGBoost completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during hyperparameter tuning for XGBoost: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 17:00:23,829 - INFO - Models saved successfully at ../models/random_search_xgb.joblib and ../models/best_xgb.joblib\n"
     ]
    }
   ],
   "source": [
    "# path to model\n",
    "random_search_xgb_path = '../models/random_search_xgb.joblib'\n",
    "best_xgb_path = \"../models/best_xgb.joblib\"\n",
    "\n",
    "try:\n",
    "    dump(random_search_xgb, random_search_xgb_path)\n",
    "    dump(best_xgb, best_xgb_path)\n",
    "    logging.info(f\"Models saved successfully at {random_search_xgb_path} and {best_xgb_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the models: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 17:03:01,245 - INFO - Best XGBoost model evaluated successfully and added to DataFrame\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    xgb_results = evaluate_model(best_xgb, X_train_scaled, y_train_encoded, X_test_scaled, y_test_encoded)\n",
    "    # Adding xgboost scores to a df\n",
    "    all_model_scores2 = pd.concat([all_model_scores2, pd.DataFrame([xgb_results])], ignore_index=True)\n",
    "    logging.info(\"Best XGBoost model evaluated successfully and added to DataFrame\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while evaluating the model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models Metrics: Tuned vs Default Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 17:05:43,642 - INFO - First three rows dropped successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Precision</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.766333</td>\n",
       "      <td>0.778608</td>\n",
       "      <td>0.767826</td>\n",
       "      <td>0.772274</td>\n",
       "      <td>0.762439</td>\n",
       "      <td>0.772403</td>\n",
       "      <td>0.762131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.701171</td>\n",
       "      <td>0.677033</td>\n",
       "      <td>0.703363</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.673792</td>\n",
       "      <td>0.698474</td>\n",
       "      <td>0.673577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.796443</td>\n",
       "      <td>0.768200</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.771682</td>\n",
       "      <td>0.792134</td>\n",
       "      <td>0.763903</td>\n",
       "      <td>0.792824</td>\n",
       "      <td>0.763696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Train Accuracy  Test Accuracy  Train Precision   \n",
       "0      LogisticRegression        0.776557       0.766333         0.778608  \\\n",
       "1  RandomForestClassifier        0.701171       0.677033         0.703363   \n",
       "2           XGBClassifier        0.796443       0.768200         0.801739   \n",
       "\n",
       "   Test Precision  Train Recall  Test Recall  Train F1   Test F1  \n",
       "0        0.767826      0.772274     0.762439  0.772403  0.762131  \n",
       "1        0.678031      0.698324     0.673792  0.698474  0.673577  \n",
       "2        0.771682      0.792134     0.763903  0.792824  0.763696  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    all_model_scores2 = all_model_scores2.drop(columns=['F1 Score', 'Accuracy', 'Recall', 'Precision'], axis=1)\n",
    "    logging.info(\"First three rows dropped successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while dropping rows: {e}\")\n",
    "    raise\n",
    "\n",
    "# displaying dataframe\n",
    "all_model_scores2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Metrics of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 19:19:24,703 - INFO - DataFrame saved successfully to ../models/tuned_models_metrics.csv\n",
      "2023-12-24 19:19:24,704 - INFO - Function applied successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    save_data(df=all_model_scores2, folder_path=\"../models/\", file_name=\"tuned_models_metrics.csv\")\n",
    "    logging.info(\"Function applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(\"Error while applying function: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection: XGBoost Classifier Tuned Model\n",
    "\n",
    "After evaluating models with default and tuned hyperparameters, we can observe the Extreme Gradient Boosting Classifier(XGBoost) perform better than other models in all metrics. We chose F1 as the baseline metric for evaluation since it presents a balanced measure between Precision and Recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 09:05:48,748 - INFO - Starting execution of load_data\n",
      "2023-12-29 09:05:50,224 - INFO - Data loading completed successfully\n",
      "2023-12-29 09:05:50,229 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/processed/processed_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['processed_text'] = df['processed_text'].fillna('')\n",
    "# Initialize TfidfVectorizer and fit it on the full dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectorizer.fit(df['processed_text'])\n",
    "\n",
    "# Get feature names from the vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Additional feature names used during model training\n",
    "additional_features_names = ['noun_count', 'product_mentions', 'text_length', 'brand_mentions', 'adj_count', 'text_complexity']\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = np.concatenate((feature_names, additional_features_names))\n",
    "\n",
    "# Ensure you have the best XGBoost model loaded as best_xgb\n",
    "\n",
    "# Extract feature importances\n",
    "feature_importances = best_xgb.feature_importances_\n",
    "\n",
    "# Adjust the length of feature_importances to match the length of all_feature_names\n",
    "# This assumes that the first part of feature_importances corresponds to the TF-IDF features\n",
    "# and the rest are the additional features.\n",
    "feature_importances = np.concatenate((feature_importances[:len(feature_names)], feature_importances[-len(additional_features_names):]))\n",
    "\n",
    "# Map feature names to their importances\n",
    "feature_importance_dict = dict(zip(all_feature_names, feature_importances))\n",
    "\n",
    "# Convert to a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame(list(feature_importance_dict.items()), columns=['Feature', 'Importance'])\n",
    "\n",
    "# Sort the DataFrame by the absolute value of importances\n",
    "feature_importance_df = feature_importance_df.reindex(feature_importance_df.Importance.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Plot the top 10 feature importances\n",
    "top_n = 10\n",
    "top_features_df = feature_importance_df.head(top_n)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_features_df['Importance'], y=top_features_df['Feature'])\n",
    "plt.title(f'Top {top_n} Feature Importances from XGBoost')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('xgb_feature_importances.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
