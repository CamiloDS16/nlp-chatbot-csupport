{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Modeling: Sentiment Analysis For Customer Interactions In X (Formerly Twitter)\n",
    "\n",
    "This notebook is structured to guide through the preprocessing and modeling stages of a sentiment analysis project. The primary objective is to categorize X (formerly Twitter) customer support interactions into distinct sentiment classes. This involves transforming cleaned tweet data for machine learning applications and performing sentiment analysis to extract meaningful business insights.\n",
    "\n",
    "#### Preprocessing\n",
    "- **Objective**: Ready the cleaned dataset for detailed sentiment analysis and feature extraction.\n",
    "- **Key Steps**:\n",
    "  - Application of advanced NLP techniques like lemmatization and removal of stopwords to refine the text data.\n",
    "  - Execution of feature engineering to extract significant attributes from the data, including text length, frequency of product mentions, and sentiment scores.\n",
    "  - Development of additional derived features such as part-of-speech tags and named entity recognition to enhance the dataset's richness.\n",
    "\n",
    "#### Feature Extraction and Selection\n",
    "- **Objective**: Extract and identify key features for the sentiment analysis model.\n",
    "- **Methodology**:\n",
    "  - Employment of TF-IDF vectorization to numerically represent text data, highlighting word significance within the dataset.\n",
    "  - Incorporation of count-based features like noun and adjective counts, adding depth to the model's understanding.\n",
    "  - Selection of a diversified set of text-based and derived features to form a comprehensive input for the model.\n",
    "\n",
    "#### Model Building and Evaluation\n",
    "- **Objective**: Develop and evaluate models for classifying tweets into sentiment categories.\n",
    "- **Approach**:\n",
    "  - Exploration of various machine learning models including Logistic Regression, Support Vector Machine, Random Forest, and Gradient Boosting Machines.\n",
    "  - Assessment of model performance using metrics such as accuracy, precision, recall, and F1-score to gauge effectiveness.\n",
    "  - Optimization of model parameters and feature selection to enhance accuracy and performance.\n",
    "\n",
    "#### Sentiment Classification\n",
    "- **Objective**: Precise classification of customer interactions into positive, negative, or neutral sentiments.\n",
    "- **Details**:\n",
    "  - Integration of trained models for predicting sentiment labels on new data.\n",
    "  - Analysis of model predictions to gain insights into customer sentiment trends and brand performance.\n",
    "\n",
    "#### Final Model Selection and Deployment Considerations\n",
    "- **Objective**: Identify the most effective model and plan its deployment.\n",
    "- **Strategy**:\n",
    "  - Comparison of different models to select the most suitable one for sentiment classification.\n",
    "  - Discussion of potential deployment methodologies, including options for real-time analysis and integration within customer support frameworks.\n",
    "\n",
    "This notebook underscores the significance of meticulous data preparation, strategic feature engineering, and judicious model selection in sentiment analysis, aiming to showcase advanced data science proficiency and a pragmatic approach to addressing real-world problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for processing\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from joblib import load, dump\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import logging\n",
    "import warnings\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# set up spacy \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Cleaned Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 17:02:00,621 - INFO - Starting execution of load_data\n",
      "2023-12-11 17:02:01,211 - INFO - Data loading completed successfully\n",
      "2023-12-11 17:02:01,214 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/interim/cleaned_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:11:45</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:08:27</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i have sent several private messages and no on...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:49:35</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>i did</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:45:10</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is the worst customer service</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>2017-10-31 22:04:47</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>you gonna magically change your connectivity f...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id           created_at   \n",
       "0         2     115712  2017-10-31 22:11:45  \\\n",
       "1         3     115712  2017-10-31 22:08:27   \n",
       "2         5     115712  2017-10-31 21:49:35   \n",
       "3         8     115712  2017-10-31 21:45:10   \n",
       "4        12     115713  2017-10-31 22:04:47   \n",
       "\n",
       "                                                text response_tweet_id   \n",
       "0      @sprintcare and how do you propose we do that               NaN  \\\n",
       "1  @sprintcare I have sent several private messag...                 1   \n",
       "2                                 @sprintcare I did.                 4   \n",
       "3          @sprintcare is the worst customer service            9,6,10   \n",
       "4  @sprintcare You gonna magically change your co...          11,13,14   \n",
       "\n",
       "   in_response_to_tweet_id                                       cleaned_text   \n",
       "0                      1.0                  and how do you propose we do that  \\\n",
       "1                      4.0  i have sent several private messages and no on...   \n",
       "2                      6.0                                              i did   \n",
       "3                      NaN                      is the worst customer service   \n",
       "4                     15.0  you gonna magically change your connectivity f...   \n",
       "\n",
       "   sentiment  message_length  \n",
       "0     0.0000              33  \n",
       "1    -0.2960              70  \n",
       "2     0.0000               5  \n",
       "3    -0.6249              29  \n",
       "4     0.0000              71  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cleaned_text\n",
       "<class 'str'>    100000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'].apply(type).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing:\n",
    "\n",
    "We will perform a series of steps to transform the data for modeling by doing this, we ensure the consistency on responses. We will also add some engineered features that will enhance the model for the response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['cleaned_text'].apply(preprocess_text)\n",
    "df['processed_text'] = df['processed'].apply(lambda x: x['processed_text'])\n",
    "df['pos_tags'] = df['processed'].apply(lambda x: x['pos_tags'])\n",
    "df['noun_count'] = df['pos_tags'].apply(lambda tags: tags.count('NOUN'))\n",
    "df['adj_count'] = df['pos_tags'].apply(lambda tags: tags.count('ADJ'))\n",
    "# text complexity\n",
    "df['text_complexity'] = df['processed_text'].apply(lambda x: len(set(x.split())) / len(x.split()) if x.split() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:15:18,644 - INFO - DataFrame saved successfully to ../data/processed/processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved at: ../data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# saving preprocessed data to csv\n",
    "folder_path2 = '../data/'  # Adjust the path as needed\n",
    "file_name2 = 'processed/processed_data.csv'\n",
    "full_path2 = save_data(df, folder_path2, file_name2)\n",
    "\n",
    "if full_path2:\n",
    "    print(f\"DataFrame saved at: {full_path2}\")\n",
    "else:\n",
    "    print(\"Failed to save the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply NER\n",
    "df['entities'] = df['text'].apply(extract_entities)\n",
    "# count product mention\n",
    "df['product_mentions'] = df['entities'].apply(lambda ents: sum('PRODUCT' in ent for ent in ents))\n",
    "# text length in processed-lemmatized text\n",
    "df['text_length'] = df['processed_text'].apply(len)\n",
    "# brands count\n",
    "df['brand_mentions'] = df['entities'].apply(lambda ents: sum('ORG' in ent for ent in ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 18:28:47,857 - INFO - DataFrame saved successfully to ../data/processed/processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved at: ../data/processed/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "# saving preprocessed data to csv\n",
    "folder_path2 = '../data/'  # Adjust the path as needed\n",
    "file_name2 = 'processed/processed_data.csv'\n",
    "full_path2 = save_data(df, folder_path2, file_name2)\n",
    "\n",
    "if full_path2:\n",
    "    print(f\"DataFrame saved at: {full_path2}\")\n",
    "else:\n",
    "    print(\"Failed to save the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 10:25:52,083 - INFO - Starting execution of load_data\n",
      "2023-12-12 10:25:53,212 - INFO - Data loading completed successfully\n",
      "2023-12-12 10:25:53,217 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/processed/processed_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dependent variable\n",
    "def categorize_sentiment(score, pos_threshold=0.1, neg_threshold=-0.1):\n",
    "    \"\"\"\n",
    "    Categorize sentiment score into classes with error handling and logging.\n",
    "    Args:\n",
    "    score (float): Sentiment score.\n",
    "    pos_threshold (float): Threshold for positive sentiment.\n",
    "    neg_threshold (float): Threshold for negative sentiment.\n",
    "    Returns:\n",
    "    str: Sentiment category ('Positive', 'Negative', 'Neutral').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if score > pos_threshold:\n",
    "            sentiment = 'Positive'\n",
    "        elif score < neg_threshold:\n",
    "            sentiment = 'Negative'\n",
    "        else:\n",
    "            sentiment = 'Neutral'\n",
    "        return sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in categorizing sentiment: {e}\")\n",
    "        return 'Neutral'\n",
    "\n",
    "\n",
    "df['derived_sentiment'] = df['sentiment'].apply(categorize_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message_length</th>\n",
       "      <th>processed</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>text_complexity</th>\n",
       "      <th>entities</th>\n",
       "      <th>product_mentions</th>\n",
       "      <th>text_length</th>\n",
       "      <th>brand_mentions</th>\n",
       "      <th>derived_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:11:45</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>and how do you propose we do that</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>33</td>\n",
       "      <td>{'processed_text': 'propose', 'pos_tags': ['CC...</td>\n",
       "      <td>propose</td>\n",
       "      <td>['CCONJ', 'SCONJ', 'AUX', 'PRON', 'VERB', 'PRO...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 22:08:27</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i have sent several private messages and no on...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>70</td>\n",
       "      <td>{'processed_text': 'send private message respo...</td>\n",
       "      <td>send private message respond usual</td>\n",
       "      <td>['PRON', 'AUX', 'VERB', 'ADJ', 'ADJ', 'NOUN', ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:49:35</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>i did</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>{'processed_text': '', 'pos_tags': ['PRON', 'V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['PRON', 'VERB']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>115712</td>\n",
       "      <td>2017-10-31 21:45:10</td>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>9,6,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>is the worst customer service</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>29</td>\n",
       "      <td>{'processed_text': 'bad customer service', 'po...</td>\n",
       "      <td>bad customer service</td>\n",
       "      <td>['AUX', 'DET', 'ADJ', 'NOUN', 'NOUN']</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>115713</td>\n",
       "      <td>2017-10-31 22:04:47</td>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>11,13,14</td>\n",
       "      <td>15.0</td>\n",
       "      <td>you gonna magically change your connectivity f...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>71</td>\n",
       "      <td>{'processed_text': 'gon na magically change co...</td>\n",
       "      <td>gon na magically change connectivity family</td>\n",
       "      <td>['PRON', 'VERB', 'PART', 'ADV', 'VERB', 'PRON'...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  author_id           created_at   \n",
       "0         2     115712  2017-10-31 22:11:45  \\\n",
       "1         3     115712  2017-10-31 22:08:27   \n",
       "2         5     115712  2017-10-31 21:49:35   \n",
       "3         8     115712  2017-10-31 21:45:10   \n",
       "4        12     115713  2017-10-31 22:04:47   \n",
       "\n",
       "                                                text response_tweet_id   \n",
       "0      @sprintcare and how do you propose we do that               NaN  \\\n",
       "1  @sprintcare I have sent several private messag...                 1   \n",
       "2                                 @sprintcare I did.                 4   \n",
       "3          @sprintcare is the worst customer service            9,6,10   \n",
       "4  @sprintcare You gonna magically change your co...          11,13,14   \n",
       "\n",
       "   in_response_to_tweet_id                                       cleaned_text   \n",
       "0                      1.0                  and how do you propose we do that  \\\n",
       "1                      4.0  i have sent several private messages and no on...   \n",
       "2                      6.0                                              i did   \n",
       "3                      NaN                      is the worst customer service   \n",
       "4                     15.0  you gonna magically change your connectivity f...   \n",
       "\n",
       "   sentiment  message_length   \n",
       "0     0.0000              33  \\\n",
       "1    -0.2960              70   \n",
       "2     0.0000               5   \n",
       "3    -0.6249              29   \n",
       "4     0.0000              71   \n",
       "\n",
       "                                           processed   \n",
       "0  {'processed_text': 'propose', 'pos_tags': ['CC...  \\\n",
       "1  {'processed_text': 'send private message respo...   \n",
       "2  {'processed_text': '', 'pos_tags': ['PRON', 'V...   \n",
       "3  {'processed_text': 'bad customer service', 'po...   \n",
       "4  {'processed_text': 'gon na magically change co...   \n",
       "\n",
       "                                processed_text   \n",
       "0                                      propose  \\\n",
       "1           send private message respond usual   \n",
       "2                                          NaN   \n",
       "3                         bad customer service   \n",
       "4  gon na magically change connectivity family   \n",
       "\n",
       "                                            pos_tags  noun_count  adj_count   \n",
       "0  ['CCONJ', 'SCONJ', 'AUX', 'PRON', 'VERB', 'PRO...           0          0  \\\n",
       "1  ['PRON', 'AUX', 'VERB', 'ADJ', 'ADJ', 'NOUN', ...           2          3   \n",
       "2                                   ['PRON', 'VERB']           0          0   \n",
       "3              ['AUX', 'DET', 'ADJ', 'NOUN', 'NOUN']           2          1   \n",
       "4  ['PRON', 'VERB', 'PART', 'ADV', 'VERB', 'PRON'...           2          1   \n",
       "\n",
       "   text_complexity entities  product_mentions  text_length  brand_mentions   \n",
       "0              1.0       []                 0            7               0  \\\n",
       "1              1.0       []                 0           34               0   \n",
       "2              0.0       []                 0            0               0   \n",
       "3              1.0       []                 0           20               0   \n",
       "4              1.0       []                 0           43               0   \n",
       "\n",
       "  derived_sentiment  \n",
       "0           Neutral  \n",
       "1          Negative  \n",
       "2           Neutral  \n",
       "3          Negative  \n",
       "4           Neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['processed_text'].fillna('')\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "try:\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_tfidf = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "# Combine TF-IDF with other features\n",
    "    additional_features = df[['noun_count', 'product_mentions', 'text_length', 'brand_mentions', 'adj_count', 'text_complexity']].values\n",
    "    X_combined = hstack([X_tfidf, additional_features])\n",
    "except Exception as e: \n",
    "    logging.error(f\"Error while performing TfidfVectorizer and/or combining features: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 11:04:59,434 - INFO - Data successfully split into train and test sets.\n",
      "2023-12-12 11:04:59,435 - INFO - Split data function applied successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    y = df['derived_sentiment']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(X_combined, y, test_size=0.3)\n",
    "    logging.info(\"Split data function applied successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while splitting data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features: \n",
    "\n",
    "Scaling is a crucial step before training a ML model to ensure the features are within the same mean and std. Below, we will extract the count-based features (features extracted previously and stacked horizontally with main feature: TF-IDF). Then, we will use MinMaxScaler to standardize them and finally stack them back with the main and already normalized TF-IDF features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 11:15:25,850 - INFO - Count-based features scaled successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# number of count-based features\n",
    "num_count_features = 6\n",
    "\n",
    "try: # Extract count-based features from the end of each row in X_train and X_test\n",
    "    X_train_counts = X_train[:, -num_count_features:]\n",
    "    X_test_counts = X_test[:, -num_count_features:]\n",
    "\n",
    "    # Normalize these features\n",
    "    scaler = MaxAbsScaler()\n",
    "    X_train_counts_scaled = scaler.fit_transform(X_train_counts)\n",
    "    X_test_counts_scaled = scaler.transform(X_test_counts)\n",
    "\n",
    "    # Recombine with the TF-IDF features\n",
    "    X_train_scaled = hstack([X_train[:, :-num_count_features], X_train_counts_scaled])\n",
    "    X_test_scaled = hstack([X_test[:, :-num_count_features], X_test_counts_scaled])\n",
    "    logging.info(\"Count-based features scaled successfully\")\n",
    "except Exception as e: \n",
    "    logging.error(f\"Error while scaling count-based features: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding y_train and y_test for XGBoost Modeling\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for saving the datasets\n",
    "X_train_path = '../data/processed/X_train_scaled.joblib'\n",
    "X_test_path = '../data/processed/X_test_scaled.joblib'\n",
    "y_train_path = '../data/processed/y_train.joblib'\n",
    "y_test_path = '../data/processed/y_test.joblib'\n",
    "y_train_encoded_path = '../data/processed/y_train_encoded.joblib'\n",
    "y_test_encoded_path = '../data/processed/y_test_encoded.joblib'\n",
    "\n",
    "# Saving the datasets\n",
    "try:\n",
    "    dump(X_train_scaled, X_train_path)\n",
    "    logging.info(f\"X_train_scaled saved successfully at {X_train_path}\")\n",
    "\n",
    "    dump(X_test_scaled, X_test_path)\n",
    "    logging.info(f\"X_test_scaled saved successfully at {X_test_path}\")\n",
    "\n",
    "    dump(y_train, y_train_path)\n",
    "    logging.info(f\"y_train saved successfully at {y_train_path}\")\n",
    "\n",
    "    dump(y_test, y_test_path)\n",
    "    logging.info(f\"y_test saved successfully at {y_test_path}\")\n",
    "\n",
    "    dump(y_train_encoded, y_train_encoded_path)\n",
    "    logging.info(f\"y_train_encoded saved successfully at {y_train_encoded_path}\")\n",
    "\n",
    "    dump(y_test_encoded, y_test_encoded_path)\n",
    "    logging.info(f\"y_test_encoded saved successfully at {y_test_encoded_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while saving datasets: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building, Training, and Testing: Sentiment Analysis Project\n",
    "\n",
    "This section of the notebook is dedicated to building, training, and testing various machine learning models for sentiment analysis. Our goal is to classify Twitter customer support interactions into sentiment categories: positive, negative, or neutral. We have chosen four models for this task, each with distinct characteristics and strengths:\n",
    "\n",
    "#### 1. Logistic Regression\n",
    "- **Approach**: We will tune hyperparameters like regularization strength (C) and iteration count, striving for a balance between model simplicity and predictive performance.\n",
    "\n",
    "#### 2. Support Vector Machine (SVM)\n",
    "- **Approach**: We'll explore both linear and non-linear kernels, aiming to capture complex patterns in the data while maintaining model efficiency.\n",
    "\n",
    "#### 3. Random Forest Classifier\n",
    "- **Approach**: We will focus on tuning tree-specific parameters like the number of trees and tree depth to optimize performance and prevent overfitting.\n",
    "\n",
    "#### 4. Gradient Boosting Machines (XGBoost)\n",
    "- **Approach**: We'll implement careful tuning of learning rate, number of estimators, and tree complexity, aiming to enhance the model's ability to sequentially learn from misclassified data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Testing and Evaluation:\n",
    "For each model, we'll perform the following:\n",
    "- **Cross-Validation**: To ensure robustness and generalizability, we'll use cross-validation techniques during hyperparameter tuning.\n",
    "- **Model Evaluation**: Post-training, we'll assess each model on the test dataset using metrics such as accuracy, precision, recall, and F1-score, providing a holistic view of each model's performance.\n",
    "\n",
    "The selection of these models demonstrates a strategic approach to tackling a real-world sentiment analysis task, showcasing a solid grasp of data science principles and the ability to apply different machine learning techniques effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty DataFrame to store all model scores\n",
    "all_model_scores = pd.DataFrame(columns=['Model', 'F1 Score', 'Accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 17:20:15,937 - INFO - Logistic Regression evaluation completed successfully.\n",
      "2023-12-12 17:20:15,938 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Evaluate the model\n",
    "logreg_scores = evaluate_model(logreg_model, \"Logistic Regression\", X_train_scaled, y_train)\n",
    "\n",
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, logreg_scores], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classifier (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 18:54:39,855 - INFO - Support Vector Classifier(SVM) evaluation completed successfully.\n",
      "2023-12-12 18:54:39,856 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear', cache_size=1000, tol=0.01)\n",
    "\n",
    "# Evaluate the model\n",
    "svc_scores = evaluate_model(svc_model, \"Support Vector Classifier(SVM)\", X_train_scaled, y_train)\n",
    "\n",
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, svc_scores], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 19:22:28,734 - INFO - Random Forest Classifier evaluation completed successfully.\n",
      "2023-12-12 19:22:28,736 - INFO - Model scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_scores = evaluate_model(rf_model, \"Random Forest Classifier\", X_train_scaled, y_train)\n",
    "\n",
    "# Append to the master DataFrame\n",
    "try:\n",
    "    all_model_scores = pd.concat([all_model_scores, rf_scores], ignore_index=True)\n",
    "    logging.info(\"Model scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error appending model scores: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 20:06:16,574 - INFO - XGBoost Classifier evaluation completed successfully.\n",
      "2023-12-12 20:06:16,575 - INFO - XGBoost Classifier scores appended successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost model with encoded labels\n",
    "xgb_model = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Evaluate the model\n",
    "try:\n",
    "    xgb_scores = evaluate_model(xgb_model, \"XGBoost Classifier\", X_train_scaled, y_train_encoded)\n",
    "    all_model_scores = pd.concat([all_model_scores, xgb_scores], ignore_index=True)\n",
    "    logging.info(\"XGBoost Classifier scores appended successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error evaluating XGBoost Classifier: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 19:28:34,707 - INFO - X_train_scaled loaded successfully.\n",
      "2023-12-13 19:28:34,712 - INFO - X_test_scaled loaded successfully.\n",
      "2023-12-13 19:28:34,720 - INFO - y_train loaded successfully.\n",
      "2023-12-13 19:28:34,725 - INFO - y_test loaded successfully.\n",
      "2023-12-13 19:28:34,728 - INFO - y_train_encoded loaded successfully.\n",
      "2023-12-13 19:28:34,729 - INFO - y_test_encoded loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# loading the data\n",
    "# Paths where the datasets were saved\n",
    "X_train_path = '../data/processed/X_train_scaled.joblib'\n",
    "X_test_path = '../data/processed/X_test_scaled.joblib'\n",
    "y_train_path = '../data/processed/y_train.joblib'\n",
    "y_test_path = '../data/processed/y_test.joblib'\n",
    "y_train_encoded_path = '../data/processed/y_train_encoded.joblib'\n",
    "y_test_encoded_path = '../data/processed/y_test_encoded.joblib'\n",
    "\n",
    "# Loading the datasets\n",
    "try:\n",
    "    X_train_scaled = load(X_train_path)\n",
    "    logging.info(\"X_train_scaled loaded successfully.\")\n",
    "\n",
    "    X_test_scaled = load(X_test_path)\n",
    "    logging.info(\"X_test_scaled loaded successfully.\")\n",
    "\n",
    "    y_train = load(y_train_path)\n",
    "    logging.info(\"y_train loaded successfully.\")\n",
    "\n",
    "    y_test = load(y_test_path)\n",
    "    logging.info(\"y_test loaded successfully.\")\n",
    "\n",
    "    y_train_encoded = load(y_train_encoded_path)\n",
    "    logging.info(\"y_train_encoded loaded successfully.\")\n",
    "\n",
    "    y_test_encoded = load(y_test_encoded_path)\n",
    "    logging.info(\"y_test_encoded loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading datasets: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing an empty DataFrame to store all tunned model scores \n",
    "all_model_scores2 = pd.DataFrame(columns=['Model', 'F1 Score', 'Accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get model scores and store them in a df\n",
    "def get_best_model_scores(random_search_cv, model_name):\n",
    "    \"\"\"\n",
    "    Extracts the best scores from a RandomizedSearchCV object.\n",
    "    Args:\n",
    "    random_search_cv: The RandomizedSearchCV object.\n",
    "    model_name (str): Name of the model.\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with performance metrics for the best model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extracting the best scores\n",
    "        best_score = random_search_cv.best_score_\n",
    "        best_params = random_search_cv.best_params_\n",
    "        best_index = random_search_cv.best_index_\n",
    "\n",
    "        # Retrieving the scores\n",
    "        best_accuracy = random_search_cv.cv_results_['mean_test_accuracy'][best_index]\n",
    "        best_precision = random_search_cv.cv_results_['mean_test_precision_macro'][best_index]\n",
    "        best_recall = random_search_cv.cv_results_['mean_test_recall_macro'][best_index]\n",
    "        best_f1 = random_search_cv.cv_results_['mean_test_f1_macro'][best_index]\n",
    "\n",
    "        # Creating a DataFrame row\n",
    "        df_row = pd.DataFrame({\n",
    "            'Model': [f\"{model_name} (Tuned)\"],\n",
    "            'Accuracy': [best_accuracy],\n",
    "            'Precision': [best_precision],\n",
    "            'Recall': [best_recall],\n",
    "            'F1 Score': [best_f1]\n",
    "        })\n",
    "\n",
    "        logging.info(f\"Best scores for {model_name} extracted successfully.\")\n",
    "        return df_row\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in extracting best scores for {model_name}: {e}\")\n",
    "        return pd.DataFrame({\n",
    "            'Model': [f\"{model_name} (Tuned)\"],\n",
    "            'Accuracy': [None],\n",
    "            'Precision': [None],\n",
    "            'Recall': [None],\n",
    "            'F1 Score': [None]\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "190 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/camilods16/opt/anaconda3/envs/nlp-c/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "2023-12-13 20:08:35,500 - INFO - Hyperparameter tuning for Logistic Regression completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# import stats\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "# warnings ignore\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist_logreg = {\n",
    "    'C': loguniform(1e-2, 1e2),  # Log-uniform distribution\n",
    "    'solver': ['lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet', 'none']\n",
    "}\n",
    "\n",
    "# Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_logreg = RandomizedSearchCV(\n",
    "    logreg, \n",
    "    param_distributions=param_dist_logreg, \n",
    "    n_iter=100,\n",
    "    cv=5, \n",
    "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'], \n",
    "    refit='f1_macro', \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "try:\n",
    "    random_search_logreg.fit(X_train_scaled, y_train)\n",
    "    best_logreg = random_search_logreg.best_estimator_\n",
    "    logging.info(\"Hyperparameter tuning for Logistic Regression completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during hyperparameter tuning for Logistic Regression: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned LogReg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 20:21:56,096 - INFO - RandomizedSearchCV object for Logistic Regression saved successfully at ../models/random_search_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "# Assuming random_search_logreg is your RandomizedSearchCV object for Logistic Regression\n",
    "random_search_logreg_path = '../models/random_search_logreg.joblib'\n",
    "\n",
    "try:\n",
    "    dump(random_search_logreg, random_search_logreg_path)\n",
    "    logging.info(f\"RandomizedSearchCV object for Logistic Regression saved successfully at {random_search_logreg_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the RandomizedSearchCV object for Logistic Regression: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for LogReg to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:26:29,764 - INFO - Best scores for Logistic Regression extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# getting best scores to a df\n",
    "best_logreg_scores = get_best_model_scores(random_search_logreg, \"Logistic Regression\")\n",
    "# Adding logreg scores to a df\n",
    "all_model_scores2 = pd.concat([all_model_scores2, best_logreg_scores], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 20:36:37,077 - INFO - Hyperparameter tuning for Random Forest completed successfully.\n",
      "2023-12-13 20:37:12,149 - INFO - Random Forest (Tuned) evaluation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist_rf = {\n",
    "    'n_estimators': randint(50, 200), \n",
    "    'max_depth': randint(3, 20),      \n",
    "    'min_samples_split': randint(2, 10) \n",
    "}\n",
    "\n",
    "# Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    rf,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=100,  \n",
    "    cv=5,       \n",
    "    scoring={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_macro': 'precision_macro',\n",
    "        'recall_macro': 'recall_macro',\n",
    "        'f1_macro': 'f1_macro'\n",
    "    },\n",
    "    refit='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "try:\n",
    "    random_search_rf.fit(X_train_scaled, y_train)\n",
    "    best_rf = random_search_rf.best_estimator_\n",
    "    logging.info(\"Hyperparameter tuning for Random Forest completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during hyperparameter tuning for Random Forest: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 20:43:46,027 - INFO - RandomizedSearchCV object for Random Forest Model saved successfully at ../models/random_search_rf.joblib\n"
     ]
    }
   ],
   "source": [
    "# path to model\n",
    "random_search_rf_path = '../models/random_search_rf.joblib'\n",
    "\n",
    "try:\n",
    "    dump(random_search_rf, random_search_rf_path)\n",
    "    logging.info(f\"RandomizedSearchCV object for Random Forest Model saved successfully at {random_search_rf_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the RandomizedSearchCV object for Random Forest Model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:26:34,207 - INFO - Best scores for Random Forest Classifier extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# getting best scores to a dataframe\n",
    "best_rf_scores = get_best_model_scores(random_search_rf, \"Random Forest Classifier\")\n",
    "# Adding rf scores to a df\n",
    "all_model_scores2 = pd.concat([all_model_scores2, best_rf_scores], ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tunning XGBoost Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 21:30:01,484 - INFO - Hyperparameter tuning for XGBoost completed successfully.\n",
      "2023-12-13 21:31:20,292 - INFO - XGBoost (Tuned) evaluation completed successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': randint(50, 200),   # Number of gradient boosted trees\n",
    "    'learning_rate': uniform(0.01, 0.2), # Boosting learning rate\n",
    "    'max_depth': randint(3, 10)          # Maximum depth of a tree\n",
    "}\n",
    "\n",
    "# XGBoost model\n",
    "xgb = XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search_xgb = RandomizedSearchCV(\n",
    "    xgb,\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=50,  # Reduced iterations\n",
    "    cv=5,       # Reduced cross-validation folds\n",
    "    scoring={\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_macro': 'precision_macro',\n",
    "        'recall_macro': 'recall_macro',\n",
    "        'f1_macro': 'f1_macro'\n",
    "    },\n",
    "    refit='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "try:\n",
    "    random_search_xgb.fit(X_train_scaled, y_train_encoded)  # Note: use y_train_encoded for XGBoost\n",
    "    best_xgb = random_search_xgb.best_estimator_\n",
    "    logging.info(\"Hyperparameter tuning for XGBoost completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during hyperparameter tuning for XGBoost: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Tuned XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 21:34:47,994 - INFO - RandomizedSearchCV object for XGBoost Model saved successfully at ../models/random_search_xgb.joblib\n"
     ]
    }
   ],
   "source": [
    "# path to model\n",
    "random_search_xgb_path = '../models/random_search_xgb.joblib'\n",
    "\n",
    "try:\n",
    "    dump(random_search_xgb, random_search_xgb_path)\n",
    "    logging.info(f\"RandomizedSearchCV object for XGBoost Model saved successfully at {random_search_xgb_path}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error saving the RandomizedSearchCV object for XGBoost Model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:26:40,905 - INFO - Best scores for XGBoost Classifier extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# getting best scores to a dataframe\n",
    "best_xgb_scores = get_best_model_scores(random_search_xgb, \"XGBoost Classifier\")\n",
    "# Adding rf scores to a df\n",
    "all_model_scores2 = pd.concat([all_model_scores2, best_xgb_scores], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:27:28,436 - INFO - First three rows dropped successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression (Tuned)</td>\n",
       "      <td>0.764294</td>\n",
       "      <td>0.768771</td>\n",
       "      <td>0.764212</td>\n",
       "      <td>0.771032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest Classifier (Tuned)</td>\n",
       "      <td>0.676217</td>\n",
       "      <td>0.680571</td>\n",
       "      <td>0.676561</td>\n",
       "      <td>0.680433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost Classifier (Tuned)</td>\n",
       "      <td>0.749329</td>\n",
       "      <td>0.754357</td>\n",
       "      <td>0.749883</td>\n",
       "      <td>0.758123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  F1 Score  Accuracy    Recall  Precision\n",
       "6       Logistic Regression (Tuned)  0.764294  0.768771  0.764212   0.771032\n",
       "7  Random Forest Classifier (Tuned)  0.676217  0.680571  0.676561   0.680433\n",
       "8        XGBoost Classifier (Tuned)  0.749329  0.754357  0.749883   0.758123"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    all_model_scores2 = all_model_scores2.drop([0, 1, 2, 3, 4, 5])\n",
    "    logging.info(\"First three rows dropped successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while dropping rows: {e}\")\n",
    "    raise\n",
    "\n",
    "# displaying dataframe\n",
    "all_model_scores2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection: Logistic Regression Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression (Tuned) has the highest scores\n",
    "best_model = best_logreg  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 22:33:03,412 - INFO - Best Logistic Regression model saved successfully at ../models/best_logreg_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# best Logistic Regression model\n",
    "best_model_path = '../models/best_logreg_model.joblib'  \n",
    "\n",
    "# Save the model\n",
    "try:\n",
    "    dump(best_logreg, best_model_path)\n",
    "    logging.info(f\"Best Logistic Regression model saved successfully at {best_model_path}\")\n",
    "except Exception as e: \n",
    "    logging.erro(f\"Error while saving the model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving Metrics of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 23:42:08,976 - INFO - Model performance metrics saved to '../models/model_performance_metrics.csv'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    all_models_scores2.to_csv('../models/model_performance_metrics.csv', index=False)\n",
    "    logging.info(\"Model performance metrics saved to '../models/model_performance_metrics.csv'\")\n",
    "except Exception as e: \n",
    "    logging.error(f\"Error while saving metrics: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Feature Importance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 23:33:03,660 - INFO - Starting execution of load_data\n",
      "2023-12-13 23:33:04,765 - INFO - Data loading completed successfully\n",
      "2023-12-13 23:33:04,769 - INFO - Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    file_path = '../data/processed/processed_data.csv'\n",
    "    df = load_data(file_path=file_path)\n",
    "    logging.info(\"Data loaded successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error while loading the dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['processed_text'].fillna('')\n",
    "# Initialize TfidfVectorizer and fit it on the full dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_vectorizer.fit(df['processed_text'])\n",
    "\n",
    "# Get feature names from the vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Additional feature names used during model training\n",
    "additional_features_names = ['noun_count', 'product_mentions', 'text_length', 'brand_mentions', 'adj_count', 'text_complexity']\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = np.concatenate((feature_names, additional_features_names))\n",
    "\n",
    "# Extract the coefficients from the Logistic Regression model\n",
    "feature_importances = best_logreg.coef_[0]\n",
    "\n",
    "# Map feature names to their coefficients\n",
    "feature_importance_dict = dict(zip(all_feature_names, feature_importances))\n",
    "\n",
    "# Convert to a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame(list(feature_importance_dict.items()), columns=['Feature', 'Coefficient'])\n",
    "\n",
    "# Sort the DataFrame by the absolute value of coefficients\n",
    "feature_importance_df = feature_importance_df.reindex(feature_importance_df.Coefficient.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the top 10 feature importances\n",
    "top_n = 10\n",
    "top_features_df = feature_importance_df.head(top_n)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=top_features_df['Coefficient'], y=top_features_df['Feature'])\n",
    "plt.title(f'Top {top_n} Feature Importances from Logistic Regression')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importances.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
